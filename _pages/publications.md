---
layout: single
title: "Publications"
permalink: /publications/
author_profile: true
---

{% if author.googlescholar %}
  You can also find my articles on <u><a href="{{author.googlescholar}}">my Google Scholar profile</a>.</u>
{% endif %}

<!-- {% include base_path %}

{% for post in site.publications reversed %}
  {% include archive-single.html %}
{% endfor %} -->

You can also find my articles on [Google Scholar](https://scholar.google.com/citations?user=jS9csA4AAAAJ&hl=en). \* means equal contribution.


<!-- **Preprints** -->

**Conferences**

 R. Bazargani, **W. Chen**, S. Sadeghian, M. Asadi, J. Boschman, A. Darbandsari, A. Bashashati, S. Salcudean, A novel H and E color augmentation for domain invariance classification of unannotated histopathology prostate cancer images. *SPIE Medical Imaging 2023: Digital and Computational Pathology*, San Deigo, 2023, Vol. 12471, pp. 224-229. [link](https://www.spiedigitallibrary.org/conference-proceedings-of-spie/12471/124710X/A-novel-H-and-E-color-augmentation-for-domain-invariance/10.1117/12.2654040.short)

    We develop a new color augmnetation algorithm based on the color space statistics to expand the color space of the source dataset and achieve a better domain generalization on new unlabeled dataset. 

**W. Chen**, Q. Zeng, T.D. Milner, R. Bagherinasab, F. Sabiq, E. Prisman, E.H. Pang, S.E. Salcudean, Feasibility of MRI-US registration in oropharynx for transoral robotic surgery. *SPIE Medical Imaging 2023: Image-Guided Procedures, Robotic Interventions, and Modeling*, San Diego, 2023, Vol. 12466, pp. 516-522. [link](https://www.spiedigitallibrary.org/conference-proceedings-of-spie/12466/1246625/Feasibility-of-MRI-US-registration-in-oropharynx-for-transoral-robotic/10.1117/12.2655032.short)

    
    We assess the feasibility of using transcervical 3D US with TORS: we propose to place the US probe on the patient’s neck to evaluate oropharyngeal anatomy intra-operatively. We also perform the first feasibility study of image registration between transcervical 3D US and Magnetic Resonance Imaging (MRI) for the oropharynx, showing that 3D transcervical US has the clinical potential to enable intraoperative oropharynx imaging and interventional MR guidance during TORS.

 **W. Chen**, K. Mehta, B. D. Bhanushali, J. Galeotti, Ultrasound-based Tracking of Partially In-plane, Curved Needles. *2021 IEEE 18th International Symposium on Biomedical Imaging (ISBI)*, Nice, 2021, pp. 939-943. [link](https://ieeexplore.ieee.org/abstract/document/9433804)

    We propose a novel curve needle tracking method which utilizes a novel weighted RANSAC and probabilistic Hough transform with kinematics reference to track a curved and partially visible needle in ultrasound images. 
    The method works robustly and outperforms RANSAC, probabilistic Hough transform, and deep-learning based model in tracking a pre-bent needle in ultrasound phantom, and in tracking a naturally bent needle in actual tissue.

A. L. Y. Hung, **W. Chen**, J. Galeotti, Ultrasound Confidence Maps of Intensity and Structure Based on Directed Acyclic Graphs and Artifact Models. *2021 IEEE 18th International Symposium on Biomedical Imaging (ISBI)*, Nice, 2021, pp. 697-701. [link](https://arxiv.org/pdf/2011.11956.pdf) 

    We use a direct acyclic graph-based method to analyize the pixel confidence in ultrasound images. We demonstrate unique capabilities of our approach and compare it against previous confidence-measurement algorithms for shadow-detection and image-compounding tasks.

J. Mai, **W. Chen**, S. Zhang, D. Xu and Q. Wang, Performance analysis of hardware acceleration for locomotion mode recognition in robotic prosthetic control. *2018 IEEE International Conference on Cyborg and Bionic Systems (CBS)*, Shenzhen, China, 2018, pp. 607-611. [link](https://ieeexplore.ieee.org/abstract/document/8612257?casa_token=4oRbYfiN1HQAAAAA:EWHcB37LQNATyO7mY_GeaKUKzDWqhqBITOBm7TEar1kNbSKVDzcb_vSNTLvw3U2PL6u_rU4)

    We analyze the computing performance of an on-board locomotion mode recognition system which was designed for robotic transtibial prosthesis. We implemented FPGA on-board support vector machine, back-propagation neural network, quadratic discriminant analysis and linear discriminant analysis, and the experiments demonstrated that the proposed system can provide satisfactory acceleration effects on the four applied algorithms.

**Journals**

R. Moore, R. Yeung, **W. Chen**, Q. Zeng, E. Prisman, S.E. Salcudean, Enabling extracorporeal ultrasound imaging with the da Vinci robot for transoral robotic surgery: a feasibility study. *International Journal of Computer Assisted Radiology and Surgery*, 2024. [IJCARS](https://link.springer.com/article/10.1007/s11548-024-03160-9).

    We evaluate using an additional robotic (4th) arm on the da Vinci Surgical System to perform extracorporeal US neck scanning in TORS. The robotic US tasks took longer than freehand US but has close operator-rated performance.

**W. Chen**, M. Kalia, Q. Zeng, E.H. Pang, R. Bagherinasab, T.D. Milner, F. Sabiq, E. Prisman, S.E. Salcudean, Towards Transcervical Ultrasound Image Guidance for Transoral Robotic Surgery. *International Journal of Computer Assisted Radiology and Surgery*, 2023. [IJCARS](https://link.springer.com/article/10.1007/s11548-023-02898-y), [preprint](https://arxiv.org/abs/2211.16544)

    We propose and carry out preliminary evaluations of a US-guided AR system for TORS, with the transducer placed on the neck for a transcervical view. Firstly, we perform a novel MRI-transcervical 3D US registration study. Secondly, we develop a US-robot calibration method with an optical tracker and an AR system to display the anatomy mesh model in the real-time endoscope images inside the surgeon console. We demonstrate the first proof-of-concept transcervical US-guided AR system for TORS and the feasibility of trans-cervical 3D US-MRI registration. Our results show that trans-cervical 3D US is a promising technique for TORS image guidance.

Q. Wang et al., An Underwater Lower-Extremity Soft Exoskeleton for Breaststroke Assistance. *IEEE Transactions on Medical Robotics and Bionics*, vol. 2, no. 3, pp. 447-462, Aug. 2020. [link](https://ieeexplore.ieee.org/document/9090211)

    We designed an underwater lower-extremity soft exoskeleton called Powered Swimsuit to assist the wearer in breaststroke with fins. The assistive force was applied to the bottom of the fins via soft cables. During the propelling period of the stroke cycle, the cables pulled the ankle joints to provide assistance to plantar flexion. 

Y. Feng\*, **W. Chen\***, and Q. Wang, A strain gauge based locomotion mode recognition method using convolutional neural network. *Advanced Robotics*, vol. 33, no. 5, pp. 254-263, Jan. 2019. [link](https://www.tandfonline.com/doi/abs/10.1080/01691864.2018.1563500)


    We propose a novel locomotion mode recognition method based on convolutional neural network and strain gauge signals. The overall three-class locomotion mode recognition accuracy shows that the strain gauge contains information of locomotion modes, and the convolutional neural network has the capacity of extracting features from raw signals.


**Workshops**

**W. Chen**, A. Schmidt, E. Prisman, S. Salcudean, PIPsUS: Self-Supervised Point Tracking in Ultrasound. *International Workshop on Advances in Simplifying Medical Ultrasound (ASMUS),* 2024, pp. 47–57. [link](https://link.springer.com/chapter/10.1007/978-3-031-73647-6_5), [preprint](https://arxiv.org/abs/2403.04969)

    We develop a new pixel tracking model in ultrasound and a new self-supervised teacher-student training to utilizes a long-term point-tracking model trained for RGB images as a teacher to guide the model to learn realistic motions and use data augmentation to enforce tracking from US appearance.

A. L. Y. Hung, Z. Sun, **W. Chen**, J. Galeotti, Hierarchical Probabilistic Ultrasound Image Inpainting via Variational Inference. *Deep Generative Models, and Data Augmentation, Labelling, and Imperfections (DGM4MICCAI)*, 2021, pp. 83-92. [link](https://link.springer.com/chapter/10.1007/978-3-030-88210-5_7)

    

G. R. Gare\*, **W. Chen\***, A. L. Y. Hung, E. Chen, H. V. Tran, T. Fox, P. Lowery, K. Zamora, B. P. deBoisblanc, R. L. Rodriguez, J. Galeotti, The Role of Pleura and Adipose in Lung Ultrasound AI. *MICCAI 2021 workshop on Lessons Learned from the development and application of medical imaging-based AI technologies for combating COVID-19*, 2021, PP. 141-149. [link](https://link.springer.com/chapter/10.1007/978-3-030-90874-4_14)


**Master Thesis**

**W. Chen**, Ultrasound-based Needle Tracking and Lateral Manipulation Planning for Common Needle Steering. *Carnegie Mellon University*, 2021. [link](https://www.ri.cmu.edu/publications/ultrasound-based-needle-tracking-and-lateral-manipulation-planning-for-common-needle-steering/)